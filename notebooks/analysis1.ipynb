{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connor Doman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research question/interests\n",
    "\n",
    "Briefly describe your research question or interests here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/raw/Bike-Sharing-Dataset/hour.csv')\n",
    "\n",
    "display(df.sort_values('weekday'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (Which is Basically Task 1)\n",
    "\n",
    "### 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Understanding variables\n",
    "hour_df = pd.read_csv('../data/raw/Bike-Sharing-Dataset/hour.csv')\n",
    "display(hour_df.shape)\n",
    "display(hour_df.nunique(axis=0))\n",
    "display(hour_df.head())\n",
    "display(hour_df.describe())\n",
    "display(hour_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Columns With More Than 40% Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NA_cols = hour_df.isna().sum()\n",
    "\n",
    "def na_filter(na, threshold = 0.4):\n",
    "    \"\"\"Filter columns with more than 40% null values\"\"\"\n",
    "    col_pass = []\n",
    "    for i in na.keys():\n",
    "        if na[i]/hour_df.shape[0] < threshold:\n",
    "            col_pass.append(i)\n",
    "    return col_pass\n",
    "\n",
    "hour_df = hour_df[na_filter(NA_cols)]\n",
    "display(hour_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Columns `yr`, `mnth`, `atemp`, `windspeed`, and `instant`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "for c in ['instant', 'mnth', 'yr', 'atemp', 'windspeed']:\n",
    "    if c not in hour_df.columns:\n",
    "        continue\n",
    "    hour_df = hour_df.drop(c, axis=1)\n",
    "display(hour_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Rows That are Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop null Values -> there are none\n",
    "hour_df = hour_df.dropna(axis=0)\n",
    "display(hour_df.shape)\n",
    "display(hour_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No processing necesssary outside of cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Wrangle Data\n",
    "\n",
    "#### Reorder columns to be more relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col_order = ['dteday', 'hr', 'cnt', 'casual', 'registered', 'season', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'hum']\n",
    "display(hour_df[new_col_order].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hours = pd.read_csv('../data/raw/Bike-Sharing-Dataset/hour.csv')\n",
    "\n",
    "# Method chaining\n",
    "\n",
    "new_col_order = ['date', 'hour', 'count', 'casual', 'reg', 'season', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'hum']\n",
    "\n",
    "hours = (hours.drop(['instant', 'mnth', 'yr', 'atemp', 'windspeed'], axis=1)\n",
    "         .dropna(axis=0)\n",
    "         .rename(columns={\"dteday\": \"date\", \"hr\": \"hour\", \"cnt\": \"count\", \"registered\": \"reg\"})\n",
    "         .sort_values(\"count\", ascending=False))[new_col_order]\n",
    "\n",
    "display(hours.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap Method Chain in a Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process(url_or_path_to_csv_file):\n",
    "    # Method Chain 1 (Load data and deal with missing data)\n",
    "    \n",
    "    new_col_order = ['date', 'hour', 'count', 'casual', 'reg', 'season', 'holiday', 'weekday', 'workingday', 'weather', 'temp', 'humidity']\n",
    "    \n",
    "    df1 = (\n",
    "        pd.read_csv(url_or_path_to_csv_file)[new_col_order]\n",
    "        .drop(['instant', 'mnth', 'yr', 'atemp', 'windspeed'], axis=1)\n",
    "        .dropna(axis=0)\n",
    "        .rename(columns={\"dteday\": \"date\", \"hr\": \"hour\", \"cnt\": \"count\", \"hum\": \"humidity\"})\n",
    "        .sort_values(\"count\", ascending=False)\n",
    "    )\n",
    "    \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import from External File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import project_functions1 as pf\n",
    "df = pf.load_and_process('../data/raw/Bike-Sharing-Dataset/hour.csv')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What days of the week have the most bike rentals?\n",
    "- What holidays have the most bike rentals?\n",
    "- What weather conditions have the most bike rentals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df_to_analyze = pf.load_and_process('../data/raw/Bike-Sharing-Dataset/hour.csv')\n",
    "\n",
    "# SELECT AVG(count) AS avgCount FROM df_to_analyze GROUP BY weekday\n",
    "day_of_the_week = df_to_analyze.loc[:, ['count', 'weekday']].groupby(['weekday'], as_index=False).mean().round().sort_values('count', ascending=False)\n",
    "\n",
    "# display(day_of_the_week)\n",
    "\n",
    "ax = sns.barplot(data=day_of_the_week, x='weekday', y='count')\n",
    "ax.set_title('Average Count of Bikes Rented by Day of the Week')\n",
    "ax.set(xlabel='Day of the Week', ylabel='Average Rentals')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the days of the week with the most bike rentals are 4 (Friday) and 5 (Saturday). These make sense, as these are the days that people are most likely to be off work later in the day and have time to ride bikes.\n",
    "\n",
    "This begs another question, which time of day has the most bike rentals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT AVG(count) AS avgCount FROM df_to_analyze GROUP BY hour\n",
    "hour_of_the_day = df_to_analyze.loc[:, ['count', 'hour']].groupby(['hour'], as_index=False).mean().round().sort_values('count', ascending=False)\n",
    "\n",
    "# display(hour_of_the_day)\n",
    "\n",
    "ax = sns.barplot(data=hour_of_the_day, x='hour', y='count')\n",
    "ax.set_title(\"Average Rentals by Hour of the Day\")\n",
    "ax.set(xlabel='Time', ylabel='Average Rentals')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that 17:00h, or 5pm, has the most rentals on any given day. This also makes sense, as it is a rush hour commuter time. The next highest hours are 6pm and 8am, which are also rush hour times.\n",
    "\n",
    "What about holidays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT SUM(count) AS totalCount FROM df_to_analyze WHERE holiday = 1 GROUP BY date HAVING ORDER BY totalCount DESC;\n",
    "holiday = df_to_analyze[['date', 'count']].loc[df['holiday'] == 1].groupby(['date',], as_index=False).sum().sort_values('count', ascending=False)\n",
    "#.groupby(['holiday'], as_index=False).mean().round().sort_values('count', ascending=False)\n",
    "\n",
    "ax = sns.barplot(data=holiday, x='date', y='count')\n",
    "ax.set_title(\"Total Count of Bikes Rented on Holidays\")\n",
    "ax.set(xlabel='Date', ylabel='Total Count')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The single day with the most rentals was July 4, 2012, which makes sense. Surprisingly, the days with next most rentals were Easter 2012 and Veteran's Day 2012. While Veteran's Day was surprising, it makes sense as there are parades and processions and a lot of outdoor gatherings. Easter makes less sense outside of the fact that it is a day many people have off work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT AVG(count) AS avgCount FROM df_to_analyze WHERE date LIKE '%-11-%' GROUP BY date;\n",
    "# november = df_to_analyze[['date', 'count']].loc[df['date'].str.contains('2012-11-')].groupby(['date',], as_index=False).mean().round().sort_values('count', ascending=False).mean().round()\n",
    "# november = df_to_analyze.groupby(pd.PeriodIndex(df['date'], freq=\"D\"))['count'].sum().mean()\n",
    "\n",
    "display(f\"Average rentals in November 2012: {pf.get_avg_from_month(df_to_analyze, 11, year=2012)}\")\n",
    "display(f\"Rentals on November 12, 2012: {pf.get_avg_from_month(df_to_analyze, 11, day=12, year=2012)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the rentals on Veteran's Day are still over 20% higher than the average rental in November that year, which indicates the circumstance of Veteran's Day was a major factor in the high rentals. This day was a Monday, too, which removes the implication that it was a weekend day or people were out late."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>count</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14773</th>\n",
       "      <td>2012-09-12</td>\n",
       "      <td>18:00h</td>\n",
       "      <td>977</td>\n",
       "      <td>91</td>\n",
       "      <td>886</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14964</th>\n",
       "      <td>2012-09-20</td>\n",
       "      <td>17:00h</td>\n",
       "      <td>976</td>\n",
       "      <td>91</td>\n",
       "      <td>885</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14748</th>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>17:00h</td>\n",
       "      <td>970</td>\n",
       "      <td>168</td>\n",
       "      <td>802</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14725</th>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>18:00h</td>\n",
       "      <td>968</td>\n",
       "      <td>111</td>\n",
       "      <td>857</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15084</th>\n",
       "      <td>2012-09-25</td>\n",
       "      <td>17:00h</td>\n",
       "      <td>967</td>\n",
       "      <td>107</td>\n",
       "      <td>860</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11304</th>\n",
       "      <td>2012-04-21</td>\n",
       "      <td>5:00h</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>2011-01-20</td>\n",
       "      <td>4:00h</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>2011-01-20</td>\n",
       "      <td>3:00h</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>2011-02-16</td>\n",
       "      <td>3:00h</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6134</th>\n",
       "      <td>2011-09-18</td>\n",
       "      <td>4:00h</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17379 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date    hour  count  casual  registered  season  holiday  \\\n",
       "14773  2012-09-12  18:00h    977      91         886       3        0   \n",
       "14964  2012-09-20  17:00h    976      91         885       3        0   \n",
       "14748  2012-09-11  17:00h    970     168         802       3        0   \n",
       "14725  2012-09-10  18:00h    968     111         857       3        0   \n",
       "15084  2012-09-25  17:00h    967     107         860       4        0   \n",
       "...           ...     ...    ...     ...         ...     ...      ...   \n",
       "11304  2012-04-21   5:00h      1       0           1       2        0   \n",
       "435    2011-01-20   4:00h      1       0           1       1        0   \n",
       "434    2011-01-20   3:00h      1       0           1       1        0   \n",
       "1041   2011-02-16   3:00h      1       0           1       1        0   \n",
       "6134   2011-09-18   4:00h      1       1           0       3        0   \n",
       "\n",
       "         weekday  workingday  weather  temp  humidity  \n",
       "14773  Wednesday           1        1  0.66      0.44  \n",
       "14964   Thursday           1        1  0.64      0.50  \n",
       "14748    Tuesday           1        1  0.70      0.28  \n",
       "14725     Monday           1        1  0.62      0.35  \n",
       "15084    Tuesday           1        1  0.66      0.39  \n",
       "...          ...         ...      ...   ...       ...  \n",
       "11304   Saturday           0        1  0.50      0.82  \n",
       "435     Thursday           1        1  0.26      0.56  \n",
       "434     Thursday           1        1  0.26      0.56  \n",
       "1041   Wednesday           1        2  0.20      0.47  \n",
       "6134      Sunday           0        1  0.44      0.77  \n",
       "\n",
       "[17379 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Export to CSV\n",
    "import project_functions1 as pf1\n",
    "import pandas as pd\n",
    "df = pf1.load_and_process('../data/raw/Bike-Sharing-Dataset/hour.csv')\n",
    "df.to_csv('../data/processed/connor_hour.csv', index=False)\n",
    "\n",
    "# print(pd.read_csv('../data/raw/Bike-Sharing-Dataset/hour.csv').columns)\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
